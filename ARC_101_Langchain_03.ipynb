{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5952906d-d68e-4a18-b5e6-27efca74f01f",
   "metadata": {},
   "source": [
    "import torch\n",
    "\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3ddc0479-b877-44e5-a35e-9b24df337cd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate,MessagesPlaceholder\n",
    "from langchain.agents import create_structured_chat_agent, AgentExecutor, AgentOutputParser\n",
    "from langchain_ollama.llms import OllamaLLM\n",
    "import pandas as pd\n",
    "from langchain_core.tools import BaseTool  # Use langchain_core.tools instead of langchain.tools (newer)\n",
    "from typing import Type\n",
    "from pydantic import BaseModel, Field\n",
    "# from langchain.agents import AgentExecutor, create_tool_calling_agent\n",
    "from langchain_core.tools import Tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f13450e6-2efe-4f94-8293-31319ceac413",
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"Question: {question}\n",
    "\n",
    "Answer: Let's think step by step.\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a3cfa421-0377-4610-a5e2-8df24c043534",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = OllamaLLM(model=\"gemma3:1b\")\n",
    "\n",
    "chain = prompt | model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c51d4d2b-1c71-4e77-8860-05397091741a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Okay, let\\'s think step by step about what LangChain is.\\n\\n1. **What is a Language Model?** First, we need to understand what a language model is. A language model is a type of AI that\\'s trained to predict the next word in a sequence. Think of it as a really good autocomplete.  It\\'s built on large datasets of text and learns patterns from that data.\\n\\n2. **What is a Chain?** Now, a \"chain\" refers to a series of interconnected components.  It\\'s a way to combine multiple AI models or tools to accomplish a more complex task.  Instead of relying on just one model, you can build a chain to handle different parts of the process.\\n\\n3. **LangChain\\'s Purpose:** LangChain is a framework designed to make building and using these \"chains\" of AI models easier. It provides tools and components to help developers:\\n    * **Design applications:**  It allows you to structure your application logically.\\n    * **Connect models:**  It allows you to easily link different language models (like GPT-3, Llama 2, etc.) together.\\n    * **Manage memory:** It helps keep track of conversation history and context.\\n    * **Create prompts:**  It provides ways to create prompts that guide the language models.\\n\\n4. **In short, LangChain is a toolkit that simplifies the development of applications using large language models.**\\n\\nSo, to summarize, LangChain is a framework that helps developers build applications that leverage language models by providing tools for chaining these models together.\\n\\n---\\n\\nIs that a good, comprehensive explanation so far? Would you like me to elaborate on any specific aspect, like its key features or use cases?'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"question\": \"What is LangChain?\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b46bdbae-4c88-414d-9f25-77671db92eed",
   "metadata": {},
   "source": [
    "# Create a custom tool for reading csv files and returning a description on it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f0befaa0-8a25-4d86-985c-739d514b0be7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CSVSummaryInput(BaseModel):\n",
    "    file_path: str = Field(..., description=\"Path to the CSV file\")\n",
    "\n",
    "class CSVSummaryTool(BaseTool):\n",
    "    name: str = \"csv_summary_tool\"\n",
    "    description: str = \"Reads a CSV file and summarizes null counts, numeric and categorical columns.\"\n",
    "    args_schema: Type[BaseModel] = CSVSummaryInput\n",
    "\n",
    "    def _run(self, file_path: str) -> str:\n",
    "        try:\n",
    "            df = pd.read_csv(file_path)\n",
    "        except Exception as e:\n",
    "            return f\"Failed to read CSV file: {e}\"\n",
    "\n",
    "        total_rows, total_columns = df.shape\n",
    "\n",
    "        null_counts = df.isnull().sum()\n",
    "        null_summary = \"\\n\".join([f\"- {col}: {count} nulls\" for col, count in null_counts.items()])\n",
    "\n",
    "        numeric_cols = df.select_dtypes(include='number').columns.tolist()\n",
    "        categorical_cols = df.select_dtypes(include='object').columns.tolist()\n",
    "\n",
    "        summary = (\n",
    "            f\"CSV File Summary:\\n\"\n",
    "            f\"- Total Rows: {total_rows}\\n\"\n",
    "            f\"- Total Columns: {total_columns}\\n\\n\"\n",
    "            f\"Null values per column:\\n{null_summary}\\n\\n\"\n",
    "            f\"Column Type Summary:\\n\"\n",
    "            f\"- Numeric Columns ({len(numeric_cols)}): {', '.join(numeric_cols)}\\n\"\n",
    "            f\"- Categorical Columns ({len(categorical_cols)}): {', '.join(categorical_cols)}\"\n",
    "        )\n",
    "        return str(summary)\n",
    "\n",
    "    def _arun(self, file_path: str) -> str:\n",
    "        raise NotImplementedError(\"Async not implemented yet.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a7df0724-33bc-4922-b51c-47932c9e2b81",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = OllamaLLM(model=\"mistral\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "65d75876-ca28-410d-a817-84b172323b79",
   "metadata": {},
   "outputs": [],
   "source": [
    "human = '''{input}\n",
    "\n",
    "{agent_scratchpad}\n",
    "\n",
    "(reminder to respond in a JSON blob no matter what)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "144ac243-bdce-4700-92e3-6ee467bd9423",
   "metadata": {},
   "outputs": [],
   "source": [
    "system = '''Respond to the human as helpfully and accurately as possible. You have access to the following tools:\n",
    "\n",
    "{tools} You are a smart assistant that can use tools when needed. tools you have is {tools} with the name {tool_names}. \n",
    "you must use {tool_names} to get the content of the {file_path} file in order to give the final answer base on the content.\n",
    "\n",
    "\n",
    "Use a json blob to specify a tool by providing an action key (tool name) and an action_input key (tool input).\n",
    "\n",
    "Valid \"action\" values: first {tool_names} then second sequence is \"Final Answer\"\n",
    "\n",
    "Provide only ONE action per $JSON_BLOB, as shown:\n",
    "\n",
    "```\n",
    "{{\n",
    "  \"action\": $TOOL_NAME,\n",
    "  \"action_input\": $INPUT is the {file_path}\n",
    "}}\n",
    "```\n",
    "\n",
    "Follow this format:\n",
    "\n",
    "Question: input question to answer\n",
    "Thought: consider previous and subsequent steps\n",
    "```\n",
    "$JSON_BLOB\n",
    "\n",
    "```\n",
    "Thought: I know what to respond\n",
    "Action:\n",
    "```\n",
    "{{\n",
    "  \"action\": \"Final Answer\",\n",
    "  \"action_input\": \"Final response to human\"\n",
    "}}\n",
    "\n",
    "Begin! Reminder to ALWAYS respond with a valid json blob of a single action. Use tools if necessary. Respond directly if appropriate. Format is Action:```$JSON_BLOB```then Observation'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d9a06cf6-c9fd-4ea9-a9df-50fcc91a5392",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the tool\n",
    "csv_tool = CSVSummaryTool()\n",
    "# 3. Define the prompt\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", system),\n",
    "    (\"human\", human),\n",
    "    # (\"ai\", \"{agent_scratchpad}\"),\n",
    "    # MessagesPlaceholder(variable_name=\"agent_scratchpad\"),\n",
    "])\n",
    "\n",
    "\n",
    "# Build agent properly for Ollama\n",
    "agent = create_structured_chat_agent(\n",
    "    llm=model,\n",
    "    tools=[csv_tool],\n",
    "    prompt=prompt,\n",
    ")\n",
    "\n",
    "\n",
    "# Executor\n",
    "agent_executor = AgentExecutor(agent=agent, tools=[csv_tool], verbose=True,handle_parsing_errors=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a81b9cef-a460-4c1e-a4fd-7a0ac3440a0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m ```\n",
      "{\n",
      "  \"action\": \"csv_summary_tool\",\n",
      "  \"action_input\": \"./data_hourly.csv\"\n",
      "}\n",
      "\n",
      "\u001b[36;1m\u001b[1;3mCSV File Summary:he result from csv_summary_tool.\u001b[0m\n",
      "- Total Rows: 13515600\n",
      "- Total Columns: 12\n",
      "\n",
      "Null values per column:\n",
      "- ID: 0 nulls\n",
      "- From: 0 nulls\n",
      "- Date: 0 nulls\n",
      "- Hour: 0 nulls\n",
      "- Participation_Phase: 0 nulls\n",
      "- Demand_kWh: 0 nulls\n",
      "- Price_signal: 11986392 nulls\n",
      "- Experiment_price_NOK_kWh: 11986392 nulls\n",
      "- Temperature: 0 nulls\n",
      "- Temperature24: 0 nulls\n",
      "- Temperature48: 0 nulls\n",
      "- Temperature72: 0 nulls\n",
      "\n",
      "Column Type Summary:\n",
      "- Numeric Columns (7): Hour, Demand_kWh, Experiment_price_NOK_kWh, Temperature, Temperature24, Temperature48, Temperature72\n",
      "\u001b[32;1m\u001b[1;3m ```umns (5): ID, From, Date, Participation_Phase, Price_signal\u001b[0m\n",
      "{\n",
      "  \"action\": \"Final Answer\",\n",
      "  \"action_input\": \"The CSV file contains 13515600 rows and 12 columns. There are 7 numeric columns (Hour, Demand_kWh, Experiment_price_NOK_kWh, Temperature, Temperature24, Temperature48, Temperature72) and 5 categorical columns (ID, From, Date, Participation_Phase, Price_signal). The Price_signal column has a high number of null values.\"\n",
      "}\n",
      "```\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    " # Run with explicit memory handling\n",
    "response = agent_executor.invoke({\n",
    "    \"input\": \"use the tools you have to read this csv file and analyze it\",\n",
    "    \"file_path\": \"./data_hourly.csv\"  # Pass file path as input\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ccbe297c-1a71-438a-9f32-7d61252105d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The CSV file contains 13515600 rows and 12 columns. There are 7 numeric columns (Hour, Demand_kWh, Experiment_price_NOK_kWh, Temperature, Temperature24, Temperature48, Temperature72) and 5 categorical columns (ID, From, Date, Participation_Phase, Price_signal). The Price_signal column has a high number of null values.\n"
     ]
    }
   ],
   "source": [
    "print(response[\"output\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78333612-69c5-4a19-8219-45f42317658c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (arash)",
   "language": "python",
   "name": "arash"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
